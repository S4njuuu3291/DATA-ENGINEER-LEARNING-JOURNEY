# Module 2: Core APIs ‚Äî RDD, DataFrame, and Execution Model

> **Duration:** 4 hours  
> **Prerequisites:** Module 1 completed  
> **Level:** Beginner to Intermediate

---

## üìö Module Objectives

Master Spark's core APIs and execution model:

1. RDD fundamentals and when to use them
2. DataFrame API and advantages over RDD
3. Schema management best practices
4. Transformations vs Actions execution model
5. Catalyst optimizer and query optimization

---

## üìñ Learning Path

1. **[RDD Fundamentals](01-rdd-fundamentals.md)** ‚è±Ô∏è 45 min
   - Immutable, distributed, fault-tolerant
   - Lineage graph and auto-recovery
   - When to use RDD vs DataFrame

2. **[DataFrame Basics](02-dataframe-basics.md)** ‚è±Ô∏è 50 min
   - High-level structured API
   - DataFrame vs RDD vs Pandas
   - Creating and basic operations

3. **[Schema Management](03-schema-management.md)** ‚è±Ô∏è 45 min
   - Schema inference vs explicit
   - Nested schemas
   - Production best practices

4. **[Transformations & Actions](04-transformations-actions.md)** ‚è±Ô∏è 60 min
   - Lazy vs eager execution
   - DAG and stages
   - Caching strategies

5. **[Catalyst Optimizer](05-catalyst-optimizer.md)** ‚è±Ô∏è 40 min
   - Query optimization phases
   - Common optimizations
   - Using `.explain()`

---

## ‚úÖ Learning Outcomes

- [ ] Understand RDD properties and use cases
- [ ] Master DataFrame API for structured data
- [ ] Implement explicit schemas in production
- [ ] Differentiate transformations from actions
- [ ] Leverage Catalyst automatic optimizations
- [ ] Debug execution plans with `.explain()`

---

**Previous:** [‚Üê Module 1](../module-1-fundamentals/README.md) | **Next:** [Module 3: Performance ‚Üí](../module-3-performance/README.md)
