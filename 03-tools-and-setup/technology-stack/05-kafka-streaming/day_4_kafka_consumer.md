# üü¶ DAY 4 ‚Äî KAFKA CONSUMER (OFFSET, CONSUMER GROUP, & FAILURE)

> **Tujuan besar hari ini:**
> Anda memahami **bagaimana Kafka membaca data**, **bagaimana offset bekerja**, dan **kenapa Kafka tidak kehilangan data walaupun consumer mati**.

Kalau Day 3 = *cara data masuk*,
Day 4 = *cara data dibaca dengan aman*.

---

## 0Ô∏è‚É£ APA ITU CONSUMER (SECARA FILOSOFI)

Consumer **bukan ‚Äúpenerima pesan‚Äù**.

Consumer adalah:

> **pembaca log Kafka dengan posisi (offset) yang bisa maju, berhenti, atau mundur**

üìå Ini beda total dengan queue biasa:

* Queue ‚Üí pesan dihapus setelah dibaca
* Kafka ‚Üí **data tetap ada**, consumer cuma **menggeser pointer**

Ingat ini baik-baik.

---

## 1Ô∏è‚É£ MENTAL MODEL PALING PENTING (WAJIB NEMPEL)

Bayangkan Kafka seperti **file log besar**:

```
[ record 0 ][ record 1 ][ record 2 ][ record 3 ]
```

Consumer itu **bukan mengambil record**.
Consumer hanya bilang:

> ‚ÄúSaya sudah membaca sampai record ke-2‚Äù

Angka ‚Äú2‚Äù itulah **OFFSET**.

üìå Kafka **tidak peduli** Anda membaca atau tidak.
Kafka **tidak peduli** consumer hidup atau mati.
Kafka **hanya menyimpan data**.

---

## 2Ô∏è‚É£ OFFSET ITU DISIMPAN DI MANA?

Ini penting secara engineering.

Offset:

* ‚ùå **TIDAK disimpan di consumer**
* ‚ùå **TIDAK disimpan di kode Python**
* ‚úÖ **Disimpan di Kafka (internal topic)**

Nama topic internal:

```
__consumer_offsets
```

Artinya:

* Consumer mati ‚Üí offset tetap aman
* Consumer hidup lagi ‚Üí lanjut dari posisi terakhir

Inilah **alasan utama Kafka tahan failure**.

---

## 3Ô∏è‚É£ APA ITU CONSUMER GROUP?

Sekarang kita naik level.

### Definisi sederhana:

> **Consumer group = sekumpulan consumer yang bekerja sama membaca satu topic**

Tujuan:

* Parallel processing
* Scalability
* Fault tolerance

---

### Aturan emas consumer group (WAJIB HAFAL):

1. **Satu partition hanya dibaca oleh satu consumer dalam satu group**
2. Banyak consumer ‚â† selalu lebih cepat
3. Scaling dibatasi jumlah partition

Contoh:

```
Topic: crypto_trades (3 partitions)

Consumer group A:
- consumer-1 ‚Üí partition 0
- consumer-2 ‚Üí partition 1
- consumer-3 ‚Üí partition 2
```

Kalau:

* consumer mati ‚Üí partition di-reassign
* data **tidak hilang**

---

## 4Ô∏è‚É£ KENAPA CONSUMER GROUP PENTING DI INDUSTRI?

Karena:

* Microservices
* Multiple downstream systems
* Horizontal scaling

Kafka **dirancang dari awal** untuk ini.

---

## 5Ô∏è‚É£ KITA MULAI PRAKTIK ‚Äî CONSUMER DENGAN CONFLUENT

Masuk ke folder Kafka Anda.

Buat file baru:

```bash
consumer_confluent.py
```

---

## 6Ô∏è‚É£ IMPORT & CALLBACK DASAR

```python
from confluent_kafka import Consumer
import json
```

---

## 7Ô∏è‚É£ KONFIGURASI CONSUMER (INI JANTUNG DAY 4)

```python
consumer_conf = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "crypto-consumer-group",
    "auto.offset.reset": "earliest",
    "enable.auto.commit": False
}
```

Sekarang kita bedah **SATU PER SATU**.

---

### `group.id`

* Identitas consumer group
* Offset disimpan per group
* Ganti group ‚Üí baca ulang dari awal

üìå Ini sering dipakai untuk:

* Reprocessing
* Backfill

---

### `auto.offset.reset = earliest`

Artinya:

* Kalau **belum ada offset**
* Mulai baca dari **data paling awal**

Alternatif:

* `latest` ‚Üí hanya data baru

üìå Ini sangat penting saat testing.

---

### `enable.auto.commit = False`

üî• **INI PENTING**

Artinya:

* Kita **mengontrol kapan offset disimpan**
* Offset baru disimpan setelah kita yakin data sudah diproses

Kalau auto-commit:

* Consumer bisa commit offset
* Tapi processing gagal
* Data hilang secara logis

üìå Manual commit = **engineering practice yang benar**

---

## 8Ô∏è‚É£ SUBSCRIBE KE TOPIC

```python
consumer = Consumer(consumer_conf)
consumer.subscribe(["crypto_trades"])
```

Artinya:

* Consumer ini join group
* Kafka assign partition otomatis

---

## 9Ô∏è‚É£ LOOP CONSUME (PELAn, SADAR)

```python
try:
    while True:
        msg = consumer.poll(timeout=1.0)

        if msg is None:
            continue

        if msg.error():
            print(f"Consumer error: {msg.error()}")
            continue

        event = json.loads(msg.value().decode("utf-8"))
        print(
            f"Received event: {event} "
            f"from partition {msg.partition()} "
            f"offset {msg.offset()}"
        )

        # Commit offset setelah processing sukses
        consumer.commit(msg)

except KeyboardInterrupt:
    print("Stopping consumer...")

finally:
    consumer.close()
```

---

## üîü BACA INI PER BARIS (INI PENTING)

### `poll()`

* Ambil message dari Kafka
* Tidak blocking selamanya
* Kafka **tidak push**, consumer **pull**

---

### `consumer.commit(msg)`

Artinya:

> ‚ÄúSaya sudah berhasil memproses message sampai offset ini.‚Äù

üìå Offset disimpan di Kafka
üìå Kalau consumer mati setelah commit ‚Üí aman
üìå Kalau mati sebelum commit ‚Üí data akan dibaca ulang

Ini **inti reliability Kafka**.

---

## 1Ô∏è‚É£1Ô∏è‚É£ JALANKAN CONSUMER

```bash
python consumer_confluent.py
```

Sambil consumer jalan:

* Jalankan producer (Day 3)
* Lihat data masuk real-time

---

## 1Ô∏è‚É£2Ô∏è‚É£ EKSPERIMEN WAJIB (INI YANG MEMBUAT ANDA JAGO)

### Eksperimen 1 ‚Äî MATIKAN CONSUMER

* Jalankan consumer
* Stop pakai `Ctrl+C`
* Jalankan lagi

‚ùìPertanyaan:

* Apakah data lama dibaca ulang?
* Atau lanjut dari offset terakhir?

---

### Eksperimen 2 ‚Äî MATIKAN TANPA COMMIT

* Comment `consumer.commit(msg)`
* Jalankan consumer
* Stop
* Jalankan ulang

‚ùìApa yang terjadi?

üìå Ini membuktikan:

> Offset = kunci data safety

---

### Eksperimen 3 ‚Äî GANTI GROUP ID

Ubah:

```python
"group.id": "crypto-consumer-group-v2"
```

Jalankan lagi.

‚ùìKenapa data lama muncul lagi?

---

## 1Ô∏è‚É£3Ô∏è‚É£ KESALAHAN UMUM PEMULA (HINDARI INI)

‚ùå Auto-commit tanpa sadar
‚ùå Mengira Kafka push data
‚ùå Mengira offset disimpan di kode
‚ùå Mengira data hilang kalau consumer mati

Kalau Anda paham ini ‚Üí **Anda di atas rata-rata**.

---

## 1Ô∏è‚É£4Ô∏è‚É£ RANGKUMAN DAY 4 (HAFALKAN)

1. Kafka menyimpan data, bukan consumer
2. Offset adalah pointer, bukan data
3. Offset disimpan di Kafka
4. Consumer group = scaling unit
5. Commit menentukan data safety

---

## 1Ô∏è‚É£5Ô∏è‚É£ TUGAS WAJIB (TANPA KODE)

Jawab dengan kata-kata sendiri:

1. Kenapa offset harus di-commit setelah processing?
2. Apa yang terjadi kalau consumer mati sebelum commit?
3. Kenapa satu partition hanya boleh satu consumer per group?

Kalau bisa jawab **tanpa lihat kode** ‚Üí Anda benar-benar paham Kafka.

---
