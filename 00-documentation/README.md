# ðŸš€ DATA ENGINEER - Learning Hub

**Comprehensive learning materials** untuk Data Engineering - dari fundamental sampai production-ready patterns.

> ðŸ“Œ **Philosophy**: Learn by doing. Setiap folder berisi theory + hands-on examples + best practices.

---

## ðŸŽ¯ Quick Navigation

| ðŸ”´ CRITICAL (Start Here) | ðŸŸ¡ IMPORTANT | ðŸŸ¢ ADVANCED |
|-------------------------|--------------|-------------|
| [Workflow Orchestration](#-workflow-orchestration-apache-airflow) | [Cloud Services](#%EF%B8%8F-cloud-data-services) | [Performance Optimization](#-performance--optimization) |
| [Testing Framework](#-data-testing-framework) | [dbt Transformation](#-dbt-transformation) | [Security & Compliance](#-security--compliance) |
| [Python Patterns](#-python-engineering-patterns) | [API Integration](#-api-integration-patterns) | |
| [Pipeline Architecture](#%EF%B8%8F-data-pipeline-architecture) | [DevOps & Infra](#-devops--infrastructure) | |
| [Data Serialization](#-data-serialization-contracts) | | |

---

## ðŸ“š Learning Path (Recommended Order)

### ðŸ”´ Phase 1: FOUNDATIONS (Week 1-2)

#### 1. Python Engineering Patterns
ðŸ“ **Folder**: `Python_Engineering_Patterns/`

**Master:**
- âœ… Type hints & Pydantic models
- âœ… Error handling & retry mechanisms  
- âœ… HTTP clients (httpx, requests)
- âœ… Configuration management

**Why Critical:**
> Quality Python code = reliable pipelines. Type safety catches bugs early.

**Start with:**
- [Type Safety & Pydantic](Python_Engineering_Patterns/1-type-safety/)
- [Error Handling](Python_Engineering_Patterns/2-error-handling/)

---

#### 2. Data Testing Framework
ðŸ“ **Folder**: `Data_Testing_Framework/`

**Master:**
- âœ… Pytest fundamentals
- âœ… Mocking external services
- âœ… Data validation (Pydantic, Pandera)
- âœ… E2E pipeline testing

**Why Critical:**
> Testing = confidence. Deploy without fear of breaking production.

**Learning Path:**
1. [Basic Testing](Data_Testing_Framework/1-basic-testing/)
2. [Pytest Fundamentals](Data_Testing_Framework/2-pytest-fundamentals/)
3. [Data Validation](Data_Testing_Framework/3-data-validation/)
4. [Quality Checks](Data_Testing_Framework/4-quality-checks/)
5. [Testing Pipelines](Data_Testing_Framework/5-testing-pipelines/)

---

### ðŸŸ¡ Phase 2: ORCHESTRATION & CLOUD (Week 3-4)

#### 3. Workflow Orchestration (Apache Airflow)
ðŸ“ **Folder**: `tools/phase3-airflow/`

**Master:**
- âœ… DAG fundamentals & dependencies
- âœ… TaskFlow API (modern approach)
- âœ… XCom communication
- âœ… Scheduling & retry mechanisms
- âœ… Environment management dalam containers

**Why Important:**
> Airflow = production pipeline orchestration. Schedule, monitor, retry automatically.

**Learning Path:**
1. [DAG Fundamentals](tools/phase3-airflow/1-dag-fundamentals/)
2. [TaskFlow API](tools/phase3-airflow/2-taskflow-api/) â­ Modern!
3. [XCom Patterns](tools/phase3-airflow/3-xcom-patterns/)
4. [Scheduling & Retry](tools/phase3-airflow/4-scheduling-retry/)
5. [Environment Config](tools/phase3-airflow/5-environment-config/)

---

#### 4. Cloud Data Services
ðŸ“ **Folder**: `Cloud_Data_Services/`

**Master:**
- âœ… Cloud Storage (GCS) operations
- âœ… BigQuery data warehouse
- âœ… Secret Manager
- âœ… GCS â†’ BigQuery pipelines

**Why Important:**
> Modern data engineering = cloud-native. Storage + warehouse + security.

**Topics:**
- [Object Storage (GCS)](Cloud_Data_Services/1-object-storage/)
- [Data Warehouse (BigQuery)](Cloud_Data_Services/2-data-warehouse/)
- [Secrets Management](Cloud_Data_Services/3-secrets-management/)
- [Integration Patterns](Cloud_Data_Services/4-integration-patterns/)

---

#### 5. dbt Transformation
ðŸ“ **Folder**: `tools/phase5-dbt/`

**Master:**
- âœ… Layered architecture (staging â†’ mart)
- âœ… Dimensional modeling (fact & dimension)
- âœ… Incremental models
- âœ… Data quality tests
- âœ… Type casting & NULL handling

**Why Important:**
> dbt = SQL-first transformations. Version-controlled, tested, documented.

**Topics:**
- [Project Structure](tools/phase5-dbt/1-project-structure/)
- [Data Modeling](tools/phase5-dbt/2-data-modeling/)
- [Data Quality](tools/phase5-dbt/3-data-quality/)

---

### ðŸ”µ Phase 3: INTEGRATION & ARCHITECTURE (Week 5-6)

#### 6. Data Pipeline Architecture
ðŸ“ **Folder**: `Data_Pipeline_Architecture/`

**Master:**
- âœ… ETL vs ELT patterns
- âœ… Dimensional modeling (fact & dimension tables)
- âœ… Data quality (validation, deduplication)
- âœ… File formats (JSON, Parquet, CSV)
- âœ… Idempotency & partitioning

**Why Important:**
> Architecture decisions = long-term success. Choose right patterns from the start.

**Topics:**
- [ETL/ELT Patterns](Data_Pipeline_Architecture/1-etl-elt-patterns/)
- [Data Modeling](Data_Pipeline_Architecture/2-data-modeling/)
- [Data Quality](Data_Pipeline_Architecture/3-data-quality/)
- [File Formats](Data_Pipeline_Architecture/4-file-formats/)

---

#### 7. API Integration Patterns
ðŸ“ **Folder**: `API_Integration_Patterns/`

**Master:**
- âœ… REST API concepts
- âœ… Authentication (API keys, OAuth, Bearer tokens)
- âœ… Pagination patterns (offset, cursor, page-based)
- âœ… Rate limiting & exponential backoff
- âœ… Error handling & timeouts

**Why Important:**
> Modern pipelines = API integrations. Extract from 3rd-party services reliably.

---

#### 8. DevOps & Infrastructure
ðŸ“ **Folder**: `DevOps_Infrastructure/`

**Master:**
- âœ… Docker containerization
- âœ… docker-compose multi-container setup
- âœ… Git workflow & version control
- âœ… Infrastructure as Code
- âœ… CI/CD patterns

**Why Important:**
> DevOps = reproducible deployments. Same code runs everywhere (dev â†’ prod).

---

### ðŸŸ¢ Phase 4: ADVANCED TOPICS (Week 7+)

#### 9. Data Serialization Contracts
ðŸ“ **Folder**: `Data_Serialization_Contracts/`

**Topics:**
- Avro serialization for Kafka & Airflow
- Schema evolution
- In-memory serialization
- Schema registry patterns

---

#### 10. Real-Time Processing
ðŸ“ **Folder**: `tools/phase6-kafka/`, `tools/phase7-spark/`

**Topics:**
- Kafka streaming
- Spark batch/streaming processing

---

## ðŸŽ“ Learning Strategies

### For Beginners:
1. **Start with Python Patterns** - Build solid foundation
2. **Practice Testing** - Test-driven development mindset
3. **Learn Airflow Basics** - Understand DAGs & scheduling
4. **Simple Cloud Pipeline** - GCS â†’ BigQuery
5. **dbt Transformations** - SQL-based modeling

**Goal:** Build basic ETL pipeline with testing & orchestration.

---

### For Intermediate:
1. **Advanced Airflow** - TaskFlow API, dynamic DAGs
2. **Cloud Integration** - Multi-service pipelines
3. **API Integrations** - Robust HTTP clients
4. **Data Quality** - Comprehensive validation
5. **DevOps Practices** - Docker, CI/CD

**Goal:** Production-ready pipelines dengan proper error handling.

---

### For Advanced:
1. **Architecture Patterns** - Design scalable systems
2. **Performance Tuning** - Optimize queries & pipelines
3. **Security** - Credential management, RBAC
4. **Real-time Streaming** - Kafka, Spark Streaming
5. **Data Governance** - Lineage, cataloging

**Goal:** Architect & lead data platform initiatives.

---

## ðŸ“Š Tech Stack Covered

### Core Tools:
- **Orchestration**: Apache Airflow (TaskFlow API)
- **Transformation**: dbt (data build tool)
- **Cloud**: Google Cloud Platform (GCS, BigQuery, Secret Manager)
- **Testing**: pytest, pytest-httpx, Pydantic, Pandera
- **Serialization**: Apache Avro

### Programming:
- **Language**: Python 3.11+
- **Type Safety**: Pydantic, dataclasses, type hints
- **HTTP**: httpx, requests
- **Async**: asyncio, aiohttp
- **Config**: pydantic-settings, YAML

### Infrastructure:
- **Containers**: Docker, docker-compose
- **Version Control**: Git (conventional commits)
- **CI/CD**: GitHub Actions
- **IaC**: Declarative config files

---

## ðŸŽ¯ Priority Matrix

### ðŸ”´ CRITICAL (Learn First):
- âœ… Python type safety & validation
- âœ… Pytest testing framework
- âœ… Airflow DAG fundamentals
- âœ… Cloud Storage & BigQuery basics
- âœ… dbt transformations
- âœ… Docker basics
- âœ… Git version control

### ðŸŸ¡ IMPORTANT (Production Skills):
- âœ… Advanced Airflow patterns
- âœ… E2E testing strategies
- âœ… API integration patterns
- âœ… Error handling & retry
- âœ… Configuration management
- âœ… CI/CD pipelines

### ðŸŸ¢ ADVANCED (Enhancement):
- âœ… Performance optimization
- âœ… Security & compliance
- âœ… Real-time streaming
- âœ… Advanced data modeling (SCD)
- âœ… Infrastructure as Code

---

## ðŸ—‚ï¸ Complete Project Structure

```
DATA-ENGINEER/
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ 1-terminologi.txt
â”œâ”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ Python_Engineering_Patterns/       ðŸ”´ CRITICAL
â”‚   â”œâ”€â”€ 1-type-safety/
â”‚   â”œâ”€â”€ 2-error-handling/
â”‚   â”œâ”€â”€ 3-http-clients/
â”‚   â”œâ”€â”€ 4-configuration/
â”‚   â””â”€â”€ 5-async-patterns/
â”‚
â”œâ”€â”€ Data_Testing_Framework/            ðŸ”´ CRITICAL
â”‚   â”œâ”€â”€ 1-basic-testing/
â”‚   â”œâ”€â”€ 2-pytest-fundamentals/
â”‚   â”œâ”€â”€ 3-data-validation/
â”‚   â”œâ”€â”€ 4-quality-checks/
â”‚   â””â”€â”€ 5-testing-pipelines/
â”‚
â”œâ”€â”€ Data_Serialization_Contracts/
â”‚   â””â”€â”€ 1-teori-dasar/
â”‚
â”œâ”€â”€ Data_Pipeline_Architecture/        ðŸŸ¡ IMPORTANT
â”‚   â”œâ”€â”€ 1-etl-elt-patterns/
â”‚   â”œâ”€â”€ 2-data-modeling/
â”‚   â”œâ”€â”€ 3-data-quality/
â”‚   â”œâ”€â”€ 4-file-formats/
â”‚   â””â”€â”€ 5-orchestration-patterns/
â”‚
â”œâ”€â”€ Cloud_Data_Services/               ðŸŸ¡ IMPORTANT
â”‚   â”œâ”€â”€ 1-object-storage/
â”‚   â”œâ”€â”€ 2-data-warehouse/
â”‚   â”œâ”€â”€ 3-secrets-management/
â”‚   â”œâ”€â”€ 4-integration-patterns/
â”‚   â””â”€â”€ 5-testing-cloud/
â”‚
â”œâ”€â”€ API_Integration_Patterns/          ðŸŸ¡ IMPORTANT
â”‚   â”œâ”€â”€ 1-rest-api-basics/
â”‚   â”œâ”€â”€ 2-authentication/
â”‚   â”œâ”€â”€ 3-pagination/
â”‚   â”œâ”€â”€ 4-rate-limiting/
â”‚   â””â”€â”€ 5-error-handling/
â”‚
â”œâ”€â”€ DevOps_Infrastructure/             ðŸŸ¡ IMPORTANT
â”‚   â”œâ”€â”€ 1-docker/
â”‚   â”œâ”€â”€ 2-docker-compose/
â”‚   â”œâ”€â”€ 3-git-workflow/
â”‚   â”œâ”€â”€ 4-infrastructure-as-code/
â”‚   â””â”€â”€ 5-cicd/
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ phase3-airflow/               ðŸ”´ CRITICAL
â”‚   â”‚   â”œâ”€â”€ 1-dag-fundamentals/
â”‚   â”‚   â”œâ”€â”€ 2-taskflow-api/
â”‚   â”‚   â”œâ”€â”€ 3-xcom-patterns/
â”‚   â”‚   â”œâ”€â”€ 4-scheduling-retry/
â”‚   â”‚   â”œâ”€â”€ 5-environment-config/
â”‚   â”‚   â”œâ”€â”€ 6-import-resolution/
â”‚   â”‚   â”œâ”€â”€ 7-operators-comparison/
â”‚   â”‚   â”œâ”€â”€ 8-task-execution-patterns/
â”‚   â”‚   â””â”€â”€ 9-docker-compose-setup/
â”‚   â”‚
â”‚   â”œâ”€â”€ phase4-cloud/
â”‚   â”œâ”€â”€ phase5-dbt/                   ðŸŸ¡ IMPORTANT
â”‚   â”‚   â”œâ”€â”€ 1-project-structure/
â”‚   â”‚   â”œâ”€â”€ 2-data-modeling/
â”‚   â”‚   â”œâ”€â”€ 3-data-quality/
â”‚   â”‚   â”œâ”€â”€ 4-advanced-patterns/
â”‚   â”‚   â””â”€â”€ 5-testing-docs/
â”‚   â”œâ”€â”€ phase6-kafka/
â”‚   â””â”€â”€ phase7-spark/
â”‚
â””â”€â”€ project/
    â”œâ”€â”€ project_1-etl_script/
    â”œâ”€â”€ project_2-gold-silver-price/
    â”œâ”€â”€ project_3-metal-price-etl-airflow-gcp/
    â”œâ”€â”€ project_4-global-commodity/
    â””â”€â”€ project_05-realtime-crypto-price-dashboard/
```

---

## ðŸš€ Quick Start

### 1. Clone & Setup
```bash
cd DATA-ENGINEER

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Start Learning
```bash
# Begin with Python patterns
cd Python_Engineering_Patterns/1-type-safety/
cat README.md

# Run examples
python 2-pydantic-models.py

# Run tests
pytest 2-pydantic-models.py -v
```

### 3. Practice Testing
```bash
cd ../../Data_Testing_Framework/2-pytest-fundamentals/
pytest -v
```

### 4. Try Airflow
```bash
cd ../../tools/phase3-airflow/
docker-compose up
# Access: http://localhost:8080
```

---

## ðŸ“– Learning Resources

### Official Docs:
- [Apache Airflow](https://airflow.apache.org/docs/)
- [dbt Documentation](https://docs.getdbt.com/)
- [Pydantic](https://docs.pydantic.dev/)
- [pytest](https://docs.pytest.org/)
- [Google Cloud](https://cloud.google.com/docs)

### Books:
- "Fundamentals of Data Engineering" - Joe Reis & Matt Housley
- "Designing Data-Intensive Applications" - Martin Kleppmann
- "The Data Warehouse Toolkit" - Ralph Kimball

---

## ðŸŽ¯ Success Metrics

### After Phase 1 (Foundations):
- [ ] Can write type-safe Python code dengan Pydantic
- [ ] Can test data pipelines dengan pytest
- [ ] Understand testing pyramid (unit â†’ integration â†’ E2E)

### After Phase 2 (Orchestration):
- [ ] Can create Airflow DAGs dengan TaskFlow API
- [ ] Can upload/download dari GCS
- [ ] Can load data ke BigQuery
- [ ] Can write dbt models dengan tests

### After Phase 3 (Integration):
- [ ] Can design ETL/ELT pipelines
- [ ] Can integrate dengan REST APIs
- [ ] Can containerize applications dengan Docker
- [ ] Can implement CI/CD pipelines

### After Phase 4 (Advanced):
- [ ] Can architect scalable data platforms
- [ ] Can optimize query performance
- [ ] Can implement security best practices
- [ ] Can mentor junior engineers

---

## ðŸ¤ Contributing

Found errors or have improvements?
1. Create an issue
2. Submit a PR dengan clear description
3. Follow conventional commits

---

## ðŸ“ Notes

> ðŸ’¡ **Tip**: Jangan belajar semua sekaligus! Focus on one topic, practice, then move to next.

> âš ï¸ **Warning**: Examples use GCP, but concepts apply to AWS/Azure. Adjust accordingly.

> âœ… **Best Practice**: Always test code locally before deploying to cloud.

---

## ðŸŽ“ Final Words

**Data Engineering is a journey, not a destination.**

Focus on:
1. **Fundamentals** - Strong Python & testing
2. **Incremental Learning** - One topic at a time
3. **Hands-on Practice** - Build real projects
4. **Best Practices** - Quality over speed
5. **Continuous Learning** - Tech evolves fast

**Happy Learning! ðŸš€**

---

**Last Updated**: January 2026
**Maintained by**: Your Data Engineering Team
